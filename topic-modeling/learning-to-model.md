# Topicing Models
Following the principle that one doesn't understand anything one can't teach to another, I am going to explain topic modelling to myself until I know what the hell I'm doing.
Warning: I'll be blatantly copy-pasting without attribution to piece these ideas together. Internal use only. 

## My Big Explanation

### Algorithm Acronyms

LSA uses singular value decomposition to figure out how each word is related to every other word.

pLSA “discovers” a bunch of topics, attaches them to a list of words, and classifies the documents based on those topics. What if every document isn’t just a set of words, but a set of topics? In this model, our encyclopedia article about computing history might be drawn from several topics. --> groups words not just based on proximity, but also on topics. (Using, I guess, black magic.)

LDA improved upon this idea by turning it into a generative model of documents. (Takes the same three concept of words, topics, documents, instead of just generating topics from words, allows documents to be generated from topics. ?)

### Topic Modeling and Networks

####Inferring topic models from networks.
* McCallum et al. (2005). Author-Recipient-Topic (ART) Model. In ART, it is assumed that topics of letters, e-mails or direct messages between people can be inferred from knowledge of both the author and the recipient. Thus, ART takes into account the social structure of a communication network in order to generate topics.
* Dietz et al. (2007) created a model that looks at citation networks, where documents are generated by topical innovation and topical inheritance via citations.
* Nallapati et al. (2008) similarly creates a model that finds topical similarity in citing and cited documents, with the added ability of being able to predict citations that are not present.
* Blei himself joined the fray in 2009, creating the Relational Topic Model (RTM) with Jonathan Chang, which itself could summarize a network of documents, predict links between them, and predict words within them.
* Wang et al. (2011) created a model that allows for “the joint analysis of text and links between [people] in a time-evolving social network.” Their model is able to handle situations where links exist even when there is no similarity between the associated texts.

####Inferring networks from topic models.
(Using networks to visualize how documents or topics relate to one another)

Some models have been made that infer networks from non-networked text.
* Broniatowski and Magee (2010 & 2011) extended the Author-Topic Model, building a model that would infer social networks from meeting transcripts. They later added temporal information, which allowed them to infer status hierarchies and individual influence within those social networks.

Many times, however, rather than creating new models, researchers create networks out of topic models that have already been run over a set of data. Using networks, we can see how documents relate to one another, how they relate to topics, how topics are related to each other, and how all of those are related to words.
* Newton’s Chymistry project
* Elijah Meeks created a wonderful example combining topic models with networks in [Comprehending the Digital Humanities](https://dhs.stanford.edu/comprehending-the-digital-humanities/). Using fifty texts that discuss humanities computing, Elijah created a topic model of those documents and used networks to show how documents, topics, and words interacted with one another within the context of the digital humanities.
* [TopicNets](http://www.ics.uci.edu/~asuncion/pubs/TIST_11.pdf), a project that combines topic modeling and network analysis in order to create an intuitive and informative navigation interface for documents and topics. This is a great example of an interface that turns topic modeling into a useful scholarly tool, even for those who know little-to-nothing about networks or topic models.

Having a network with every document connected to every other document is scarcely useful, so generally we’ll make our decision such that each document is linked to only a handful of others. This allows for easier visualization and analysis, but it also destroys much of the rich data that went into the topic model to begin with. This information can be more fully preserved using other techniques, such as multidimensional scaling.

## Vocabulary
* tf-idf
* LSA/LDA
* MDS (Multidimensional Scaling)

## Works Read
<!--List in order read; annotate -->
[Topic Modeling and Network Analysis](http://www.scottbot.net/HIAL/?p=221) by Scott Weingart.
* Explains LSA and LDA.
* Gives examples of topic models from networks, and networks from topic models.

## Works To-Read?
[tutorial on how to create networks using MALLET and Gephi quickly and easily.](http://electricarchaeology.ca/2011/11/11/topic-modeling-with-the-java-gui-gephi/) - Prepare your corpus of text, get topics with MALLET, prune the CSV, make a network, visualize it!

[Getting Started with Mallet and Topic Modeling](http://electricarchaeology.ca/2011/08/30/getting-started-with-mallet-and-topic-modeling/) Links to sequel below

[EXTREMELY specific walkthrough of using mallet](http://programminghistorian.org/lessons/topic-modeling-and-mallet)

[a great blog post about why humanists should avoid the SVD step of using LSA](http://tedunderwood.com/2011/10/16/lsa-is-a-marvellous-tool-but-humanists-may-no-use-it-the-way-computer-scientists-do/)

## Potential Resources
[David Mimno's Topic Modeling Bibliography](http://mimno.infosci.cornell.edu/topics.html)

[Chang’s implementation of LDA and related models in R](http://cran.r-project.org/web/packages/lda/index.html) Code package; currently completely incomprehensible.