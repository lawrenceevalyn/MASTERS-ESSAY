# Topicing Models
Following the principle that one doesn't understand anything one can't teach to another, I am going to explain topic modelling to myself until I know what the hell I'm doing.
Warning: I'll be blatantly copy-pasting without attribution to piece these ideas together. Internal use only. 

## My Big Explanation

### What Do?

#### Don't Know Categories

In the beginning, there is a corpus. You don't know anything about the categories/topics it contains.

Perhaps you make a vector-space model of this corpus. If so, you describe the vector space with a matrix.

The simplest vector-space model assigns each word a weight based on its term frequency (tf) in each document. Or, there are a lot of more complicated formulae to weight words, including probabilistic methods and tf*idf.

This vector-space model is then presented in a matrix with a column for each word and a row for each document. At the intersection of each word and document is the word's weight for that document. In this matrix, each document (row) is an N-dimensional vector, with N equal to the number of words (columns). The matrix itself only has two dimensions (rows and columns) but nonetheless describes an N-dimensional vector space.

N is too many dimensions, so you use algorithms to merge similar dimensions/columns. LSA, LSI, SVD, and PCA are all different algorithms that use linear algebra to collapse columns together.

Once you've collapsed several words/columns together, your new columns are mathematical constructs that share some similarities with categories. You don't know anything.

To find out what the categories are, what you want to do to discover categories is called "Clustering" or, to AI folks "Unsupervised Learning".  Basically, the raw vectors are compared to each other using some similarity metric (in vector space:  cosine similarity metric; in probability model, some probabilistic similarity metric). You group the most similar documents into clumps using one of many, many clustering algorithms (k-means is most popular).  These groups/clusters are now your categories.

Topics are not defined by the words; the topics/concepts/classes/categories are abstract ideas. They are represented by words.

#### Do Know Categories

In the beginning, there is a corpus, and an ontology. Your corpus documents belong to X number of ontology categories. You know what all these categories are, but don't know where they are in which documents. You need to instantiate your categories, by filling them up with words.

Perhaps you make a vector-space model of this corpus. If so, you describe the vector space with a matrix. This is still the same as if you didn't know the categories.

N is still too many dimensions. You want to reduce N to the X, number of predefined known categories. A human reads a small number of documents and categorizes them. An algorithm, such as SVM or (preferably) KNN, uses these sample documents to learn how to tell the categories apart. Then you can use it to categorize the rest of the documents.

Now you know how much of each document comes from each category. Your categories are more useful than the categories generated via method 1, because you picked them out yourself.

#### Questions

At what stage does one opt for a concept-tree-distance model instead of a vector space model?

### Topic Modeling and Networks

####Inferring topic models from networks.
* McCallum et al. (2005). Author-Recipient-Topic (ART) Model. In ART, it is assumed that topics of letters, e-mails or direct messages between people can be inferred from knowledge of both the author and the recipient. Thus, ART takes into account the social structure of a communication network in order to generate topics.
* Dietz et al. (2007) created a model that looks at citation networks, where documents are generated by topical innovation and topical inheritance via citations.
* Nallapati et al. (2008) similarly creates a model that finds topical similarity in citing and cited documents, with the added ability of being able to predict citations that are not present.
* Blei himself joined the fray in 2009, creating the Relational Topic Model (RTM) with Jonathan Chang, which itself could summarize a network of documents, predict links between them, and predict words within them.
* Wang et al. (2011) created a model that allows for “the joint analysis of text and links between [people] in a time-evolving social network.” Their model is able to handle situations where links exist even when there is no similarity between the associated texts.

####Inferring networks from topic models.
(Using networks to visualize how documents or topics relate to one another)

Some models have been made that infer networks from non-networked text.
* Broniatowski and Magee (2010 & 2011) extended the Author-Topic Model, building a model that would infer social networks from meeting transcripts. They later added temporal information, which allowed them to infer status hierarchies and individual influence within those social networks.

Many times, however, rather than creating new models, researchers create networks out of topic models that have already been run over a set of data. Using networks, we can see how documents relate to one another, how they relate to topics, how topics are related to each other, and how all of those are related to words.
* Newton’s Chymistry project
* Elijah Meeks created a wonderful example combining topic models with networks in [Comprehending the Digital Humanities](https://dhs.stanford.edu/comprehending-the-digital-humanities/). Using fifty texts that discuss humanities computing, Elijah created a topic model of those documents and used networks to show how documents, topics, and words interacted with one another within the context of the digital humanities.
* [TopicNets](http://www.ics.uci.edu/~asuncion/pubs/TIST_11.pdf), a project that combines topic modeling and network analysis in order to create an intuitive and informative navigation interface for documents and topics. This is a great example of an interface that turns topic modeling into a useful scholarly tool, even for those who know little-to-nothing about networks or topic models.

Having a network with every document connected to every other document is scarcely useful, so generally we’ll make our decision such that each document is linked to only a handful of others. This allows for easier visualization and analysis, but it also destroys much of the rich data that went into the topic model to begin with. This information can be more fully preserved using other techniques, such as multidimensional scaling.

## What Have Other People Done?

[Topic Modeling Martha Ballard's Diary](http://historying.org/2010/04/01/topic-modeling-martha-ballards-diary/).
I took a lot of notes, and then accidentally deleted them.

Ted Underwood's 18th century "topic tree": [the tree](http://tedunderwood.com/18c-tree/), and [some explanation](http://tedunderwood.com/2011/04/04/revealing-the-relationships-between-topics-in-a-corpus/).
I took a lot of notes, and then accidentally deleted them.

## What Am I Trying To Do Here?

I have 208 plot summaries of novels. The summaries are roughly 1 to 5 paragraphs each, and stylistically sparse. I know the author gender and publication date for most of these novels.

The expecting topic-modeling-y questions would probably be:

1. What is the Gothic "about"? How do these topics change in prevalence over time? (Could probably be fluffed into a paper on its own if any trends emerge, but would work better in conjunction with something else.)

2. What books are the most "Gothic-y"? Or, for each thing that the Gothic is "about", what books are most representative of that thing? (If any of these are really unexpected, could be a paper on its own, with normal-English discussion of the books in question. If it's basically what people already thing, would work better in conjunction with something else.)

So the normal thing to do would be to feed my plot summaries into Mallet, and use its results to answer 1 and 2 and make them a paper together. I have a lot of more complicated questions, though, that I am really interested in. The first three basically boil down to, "What does it look like if I sort everything into the two categories of...?"

3. **Male vs Female**. My preliminary research (just counting the relative prevalence of 70 motifs listed in the index of a bibliography) suggested there are lots of things that are mostly written about by men (torture, corpses, incest) but nothing that is mostly written about by women. Does that still hold? (There are several competing conceptions of the relative prevalence of the Male Gothic vs the Female Gothic, so just fact-checking the two genres' existence could be a paper regardless of the results.)

What does a very 'male' book look like? A very 'female' book? (If these match the ways people typically define the Male and Female Gothics, this would be good for a page or two in a paper arguing something else. If they don't match, this would be a paper all on its own, and a really interesting one.)

I have about six books for which no author information is known; based on the other documents, can I make guesses about them? (I won't be able to confirm this guess, but it will make for a good page or two of discussion either way, in a paper mostly about something else.)

4. **Horror vs. Terror**. These are the two genres of Gothic novel that scholars talk about. I could give you the horror/terror designations of maybe twenty novels (because I've read them) and then we can see if we can guess it for the others! (I can't imagine that these differences would be detectable from the plot summaries; the differences are largely stylistic, so this would probably have to wait until I had a corpus of full texts. It'll make a great paper then, though.)

5. **Novel vs. Chapbook**. Some of these plot summaries are of expensive multi-volume novels, and some are of cheap 72-page chapbooks. (Everything is either a novel or a chapbook.) I wanna ask all my men-vs-women questions again, this time about novels vs. chapbooks: are they different? How are they different? (This would also be a paper all by itself.)

Upon reflection, those might actually be asking "What happens if I sort everything into these two categories, and then map some kind of network?" The next two are definitely just network questions:

6. **Names**. A lot of names get re-used across stories. A lot of names are unlikely to show up in existing lists of names. (My favourite is a woman named Euthanasia. *Mary Shelley* named a character Euthanasia.) Can a program identify which words are names, and put them in a bucket for me? With only 208 books, I can also manually delete all the non-name words from each document, and feed that new corpus to a program to put the names in a bucket and count them. Can a program make me a network map of books that share character names? (This would be a paper by itself, though the more interesting the resulting network is, the better the paper will be.)

7. **Schools**. How well does the Gothic 'canon' match the large body of Gothic texts? Do books cluster in different 'schools'? If so, are these based around the acknowledged canon, or are there schools/influential books that the canon has overlooked? 

Questions that I can already answer by myself in excel the way I did my paper on motifs:
* Do men or women write more chapbooks vs novels? How do chapbook/novel counts change over time? (A few paragraphs in a paper mostly about something else.)
* What time periods are most novels set in? What places? (These are questions a human will have to answer.) For each one, is it written about more by men or by women? How does the popularity of each one change over time? (If I do both time and place, probably a paper.)

It occurs to me, all the places where I say "paper" here, I really mean "chapter of my dissertation." Or "the entirety of my master's essay." 


## Works Read
[Topic Modeling and Network Analysis](http://www.scottbot.net/HIAL/?p=221) by Scott Weingart.
* Explains LSA and LDA.
* Gives examples of topic models from networks, and networks from topic models.

[Mom email 1](./reference/topic-modeling-reference/mom01.txt).
* v basic topic modeling explanation (familiar)
* v basic breakdown of areas in which CS researchers work

[Mom email 2](./reference/topic-modeling-reference/mom02.txt).
* explains tf-idf and LSA/LSI in more detail.
* attachment: powerpoint on TresNet (irrelevant)

[LSA is a marvellous tool, but literary historians may want to customize it for their own discipline.](http://tedunderwood.com/2011/10/16/lsa-is-a-marvellous-tool-but-humanists-may-no-use-it-the-way-computer-scientists-do/) by Ted Underwood.
* Value of LSA is not its ability to identify synonyms (which is what information retrieval (i.e., mom) uses it for)
* avoid SVD because it compresses the matrix too much/in the wrong way, to find transitive kinds of association. --> highlights semantic relationships at the cost of slightly blurring other kinds of association
* if you’re interested in “topics” that are strictly semantic, you might want to use an algorithm that reduces dimensionality with SVD. If you’re interested in discourses, sociolects, genres, or types of diction, you might use LSA without dimensionality reduction.
* Ways of weighting:
    - For the normal LSA algorithm that uses dimensionality reduction, the consensus is that “log-entropy weighting” works well. You take the log of each frequency, and multiply the whole term vector by the entropy of the vector. I have found that this also works well for humanistic purposes.
    - For LSA without dimensionality reduction, I would recommend weighting cells by subtracting the expected frequency from the observed frequency. This formula “evens the playing field” between common and uncommon words — and it does so, vitally, in a way that gives a word’s absence from a long document more weight than its absence from a short one. (Not something I care about with plot summaries, because they're all basically the same length.)
    
[Tech note](http://tedunderwood.com/tech-notes/) by Ted Underwood.
* Vector space model works better than simple Pearson’s correlation, because the “cosine similarity” measure used in a vector space model automatically gives more weight to longer documents, and to documents where a term is very strongly represented. (I don't care about document length at the plot-summary stage. Do I care about documents where a term is very strongly represented? Will I want to give longer documents more weight later?)
* INSTEAD OF TF-IDF, because we're not interested in the rarest words but just the words themselves, assess frequency as the difference between the expected occurrence of a term and the actual number of occurrences in the document. -->  this formula: occurrences of X in Y – ((Y length/corpus length) * total occurrences of X in corpus)
* This means that some components of the vector are negative, which is actually important. Otherwise the fact that a word doesn’t occur in a book of 100,000 words would have the same weight as the fact that it doesn’t occur in a play of 15,000 words, because they would both “bottom out” at zero. (Definitely something that matters when I get to full texts.)
* Of course, the “topic trees” produced by this measure are only as good as the lists of words you feed into them. (Wait, at what stage did we feed in a list of words???????)
* It may be controversial whether or not to call this “topic modeling.” If you want to describe the internal structure of a literary work, this technique of course won’t do the job directly, because it doesn’t divide works into parts. But I think it does a pretty good job of identifying the implicit thematic structure of eighteenth-century discourse as a whole, and I wouldn’t be surprised if it turned out that the internal structure of individual works is defined in large part by the way these corpus-level topics weave in and out of them.
* I actually think I... don't want to weight novels by length? Since I don't think length influences the importance of the story to readers...? Udolpho and The Veiled Picture are both just 'a reading experience'? Or does Udolpho have a bigger impact...? I think I need to be very careful about what question I'm asking.

[Document Similarity Based on Concept Tree Distance](http://citeseer.uark.edu/projects/citeseerX/papers/HT2008_short_paper.pdf), by Susan Gauch.
* Concept tree distance is an alternative to vector space models
* Traditional vector space models (i.e. LSA?) turn keyword vectors into concept vectors (i.e. collapse columns??) to reduce semantic ambiguity. However, this ignores the parent-child relationships that the keywords have inside those concept vectors.
* In this study, we introduce a novel technique to construct concept trees representing documents and we apply the tree edit distance algorithm to calculate document similarity.
* Looks like a better way to identify whether documents are related to each other. Not useful if I want to find out what concepts my corpus is mostly about, potentially useful if I want to map a network of their relationships.

[Mom email 3](./reference/topic-modeling-reference/mom03.txt).
* more explanations of vector space models and matrices; used as guide for "What Do?" explanation

[Mom email 4](./reference/topic-modeling-reference/mom04.txt).
* corrections to "What Do?" explanation

[Mom email 5](./reference/topic-modeling-reference/mom04.txt).
* clarified categories/topics

## Works To-Read?
**[Journal of Digital Humanities](http://journalofdigitalhumanities.org/2-1/dh-contribution-to-topic-modeling/)

[tutorial on how to create networks using MALLET and Gephi quickly and easily.](http://electricarchaeology.ca/2011/11/11/topic-modeling-with-the-java-gui-gephi/) - Prepare your corpus of text, get topics with MALLET, prune the CSV, make a network, visualize it!

[Getting Started with Mallet and Topic Modeling](http://electricarchaeology.ca/2011/08/30/getting-started-with-mallet-and-topic-modeling/) Links to sequel below

[EXTREMELY specific walkthrough of using mallet](http://programminghistorian.org/lessons/topic-modeling-and-mallet)

explain how the extensibility of LDA makes it quite a different kind of beast (relative to LSA): Learning author-topic models from text corpora. M Rosen-Zvi, C Chemudugunta, T Griffiths, P Smyth, M Steyvers, ACM Transactions on Information Systems (TOIS), ACM, 2010. http://www.datalab.uci.edu/papers/AT_tois.pdf

Closing out my to-read tabs:
http://tedunderwood.com/2011/03/17/a-selection-of-the-language-really-spoken-by-men/
http://tedunderwood.com/category/18c/
http://tedunderwood.com/category/methodology/
http://sappingattention.blogspot.ca/2011/01/clustering-from-search.html
http://www.matthewjockers.net/2011/09/29/the-lda-buffet-is-now-open-or-latent-dirichlet-allocation-for-english-majors/
https://ariddell.org/simple-topic-model.html
http://www.scottbot.net/HIAL/?p=19113

## Potential Resources
[David Mimno's Topic Modeling Bibliography](http://mimno.infosci.cornell.edu/topics.html)

[Chang’s implementation of LDA and related models in R](http://cran.r-project.org/web/packages/lda/index.html) Code package; currently completely incomprehensible.